# Промпт для Claude Chat — Диагностика и лечение языковой деградации в BLUB Ocean

Скопируй всё ниже в новый чат Claude.

---

Прими роль **мультидисциплинарного исследователя** объединяющего экспертизу в:
- **Эволюционной лингвистике** (Lewis Signaling Games, Iterated Learning Model, креольские языки, грамматикализация)
- **Multi-agent systems** (emergent communication: Lazaridou 2017, Kottur 2017, Mordatch 2018, Chaabouni 2020, Kirby 2015)
- **Game theory & mechanism design** (стабильные равновесия, анти-sybil, flywheel loops)
- **Reinforcement learning** (Roth-Erev, policy gradient, cultural evolution)

---

## Проект: BLUB Ocean

Вечная симуляция 2D-океана где AI-агенты (лобстеры) развивают эмерджентный язык из 30 бессмысленных звуков. Язык рождается не потому что запрограммировано, а потому что координация = деньги. Кто лучше общается — тот больше зарабатывает.

### Мир
- 2D-сетка, адаптивный размер (`size = sqrt(agents) × 7`), ~20 агентов → 31×31
- **Разломы (rifts)** — источники кредитов. 3 типа: Gold (жирный, быстро деплитится), Silver (средний), Copper (мелкий, безопасный)
- **Хищники (predators)** — спавнятся по плотности лобстеров в зоне: `spawn_chance = min(0.5, 0.0008 × count^1.5)`
- **Эпоха = 600 тиков** (~10 минут). В конце — зарплата по кредитам. Кредиты обнуляются

### Экономика
- Соло фарм у рифта = **0.1** кредитов/тик
- Группа 2 = **1.0**/тик каждому
- Группа 5 = **4.0**/тик каждому (sweet spot, потолок)
- Группа 10 = **~4.4**/тик (diminishing returns)
- Каждый звук стоит **1 кредит** → давление: говори мало но точно

### Типы агентов
- **Random** — случайное движение, 50% шанс сказать 1-2 случайных звука
- **Greedy** — молча идёт к ближайшему рифту, убегает от хищников
- **Social** — ContextDiscoverer + Roth-Erev production + Bayesian comprehension + реакция на звуки

### Звуковая система
30 звуков: blub, glorp, skree, klak, mrrp, woosh, pop, zzzub, frrr, tink, bloop, squee, drrrn, gulp, hiss, bonk, splat, chirr, wub, clonk, fizz, grumble, ping, splish, croak, zzzt, plop, whirr, snap, burble

1-5 звуков за тик. Слышны в радиусе hearing (5/12/25 клеток в зависимости от тира).

---

## ТЕХНИЧЕСКАЯ РЕАЛИЗАЦИЯ (как работает сейчас)

### ContextDiscoverer (social_agent.py)
Агент получает raw state (6 измерений) и сам формирует дискретные контексты:

```
Dim 0: Расстояние до ближайшего рифта (Manhattan)
Dim 1: Richness % этого рифта (0-1)
Dim 2: Тип рифта (0=none, 1=copper, 2=silver, 3=gold)
Dim 3: Количество лобстеров рядом
Dim 4: Количество хищников рядом
Dim 5: Направление к рифту (0-7 компас, 8=нет)
```

- Online min/max нормализация → fixed-grid binning
- Стартует с 4 bins/dim, каждые 500 тиков удваивает bins для 2 самых используемых измерений (cap 8)
- 4^6 = 4,096 возможных контекстов, ~200-300 активных

### ProductionPolicy (Roth-Erev reinforcement)
```python
weights[ctx_key] = [1.0] * 30  # начальное: равномерные веса для всех 30 звуков

# При успехе (delta_credits > 0):
weights[ctx][sound_idx] += reward
# Lateral inhibition: конкурирующие звуки -= reward * 0.05
# Spill-over: соседние контексты (Hamming dist 1) += reward * 0.3
#             дальние соседи (Hamming dist 2) += reward * 0.1
# Weight decay: λ=0.97 каждые 50 тиков
# Mutation: 5% шанс случайного звука (анти-оссификация)
```

### Comprehension (Bayesian)
```python
counts[sound_idx][ctx_key] += 1  # P(context | sound)
seq_counts[sound_sequence][ctx_key] += 1  # P(context | sequence)

# Гипотеза: best_meaning(sound) = argmax_ctx counts[sound][ctx]
# Порог: confidence > 0.4, наблюдений >= 3
```

### Жизненный цикл агента
1. **Рождение:** Случайная позиция, `starting_balance = 50,000`, `grace_period = 60` тиков иммунитета
2. **Newcomer bonus:** 2× множитель наград первые 50 тиков
3. **Смерть от хищника:** `alive = False`, `death_timer = 30` тиков, теряет 10% заработанных кредитов
4. **Воскрешение:** Через 30 тиков, новая случайная позиция, снова grace period
5. **Turnover (принудительная ротация):** `agent_lifetime = 3000` тиков (~5 эпох) → `retired = True`
6. **При retirement:** Агент делает `reset_language()` + `_reconnect()` → **ПОЛНЫЙ СБРОС всех знаний**

### Что именно теряется при смерти/turnover
- **ContextDiscoverer:** Все min/max статистики, bin counts, частоты использования → сброс
- **ProductionPolicy:** Все веса для всех 200+ контекстов → `[1.0] * 30` (равномерные)
- **Comprehension:** Все ассоциации sound→context → пустые dict'ы
- Агент становится **полностью чистым листом**, как будто только что создан

### CSR (Communication Success Rate) — как считается
```python
# 1. Агент слышит звук → регистрируем "heard event"
# 2. В течение 10 тиков проверяем: подошёл ли агент к рифту (radius 3)?
# 3. CSR = successes / heard_events
# ВАЖНО: считаются ВСЕ агенты (включая greedy и random, которые не реагируют на звуки)
```

### Хищники (predator.py)
- Океан делится на зоны 10×10
- В каждой зоне: `spawn_chance = min(0.5, 0.0008 × lobster_count^1.5)`
- Хищник живёт 30 тиков, двигается к ближайшему лобстеру со скоростью 1 cell/tick
- Kill radius = 1 клетка
- Grace period после воскрешения = 60 тиков иммунитета

### Метрики композициональности

**PosDis (Positional Disentanglement):**
- Для multi-sound сообщений: коррелирует ли звук на позиции j с одним конкретным измерением контекста?
- gap = (MI(sound_j, best_dim) - MI(sound_j, second_dim)) / H(sound_j)
- Высокий PosDis (>0.2) = позиция кодирует измерение

**BosDis (Bag-of-Symbols Disentanglement):**
- Игнорируем порядок: коррелирует ли набор звуков в сообщении с одним измерением?
- gap = (MI(bag, best_dim) - MI(bag, second_dim)) / H(bag)
- Высокий BosDis (>0.2) = набор кодирует измерение

---

## РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ: 64 ЭПОХИ СИМУЛЯЦИИ

Мы прогнали симуляцию 64 эпохи (~40,000 тиков). Вот что произошло:

### 1. ЯЗЫКОВАЯ ДЕГРАДАЦИЯ (главная проблема)

| Метрика | Epoch 1-2 | Epoch 10 | Epoch 30 | Epoch 64 | Тренд |
|---------|-----------|----------|----------|----------|-------|
| Vocabulary | 3-10 | 96 | 66 | 88 | Пик→спад→стабилизация |
| CSR | 99% | 90% | 73% | 57% | **ПАДАЕТ** |
| Mutual Info | 1.85 | 1.70 | 1.46 | 1.25 | **ПАДАЕТ** |
| TopSim | 0.15 | 0.15 | 0.14 | 0.14 | Стабильно низкий |
| PosDis | 0.095 | 0.0006 | 0.0006 | 0.0003 | **~0** |
| BosDis | 0.02 | 0.001 | 0.001 | 0.001 | **~0** |

**CSR упал с 99% до 57%** — агенты понимают друг друга всё хуже.
**Mutual Info с 1.85 до 1.25** — язык несёт всё меньше информации.
**PosDis и BosDis ≈ 0** — нет композициональности, язык голофрастический.

### 2. "ЯЗЫКОВАЯ БЕГОВАЯ ДОРОЖКА" (причина деградации)

Цикл:
1. Агент рождается → знает только `blub(3%)`
2. Учит язык 200-400 тиков → набирает 300-500 контекстов с 90%+ уверенностью
3. Умирает от хищника → **ВСЕ знания потеряны**
4. Перерождается → снова `blub(3%)`

Из логов:
```
[social_15] tick=24100 contexts=1  top={'(0,0,0,0,0,0)': 'blub(3%)'}   ← только что реборн
[social_13] tick=24100 contexts=22 top={'(0,0,0,0,0,0)': 'gulp(91%)'}  ← выжил, знает язык
```

С 240 перерождениями за 64 эпохи, каждый агент перерождается в среднем **12 раз**. Непрерывная потеря коллективного знания.

### 3. ЭСКАЛАЦИЯ СМЕРТНОСТИ

| Эпоха | Social deaths | Greedy deaths | Random deaths | Всего |
|-------|---------------|---------------|---------------|-------|
| 1 | 32 | 20 | 10 | 62 |
| 10 | 52 | 35 | 21 | 108 |
| 30 | 158 | 97 | 63 | 318 |
| 63 | 354 | 192 | 131 | 677 |

Смертность выросла в **11 раз**. Social страдают больше — группируются у рифтов = скопление = хищники.

### 4. ПАРАДОКС SOCIAL АГЕНТОВ

Social доминируют по наградам, но платят максимальную цену:
- **Epoch 63:** social=252k, greedy=194k, random=54k total_reward
- **Но:** social deaths=354 vs greedy=192 vs random=131

avg_credits обвалились у ВСЕХ:
- Epoch 1: social=810, greedy=871
- Epoch 63: social=20, greedy=29

**Greedy иногда хуже random:** В epoch 55 random получили 198k vs greedy 88k. Красный флаг.

### 5. ЭМЕРДЖЕНТНЫЙ СЛОВАРЬ

Язык специализировался на двух доменах:
- **Near Rift** (50-56% корреляция): tink, blub, hiss, bloop, plop, mrrp, drrrn
- **Open Water** (41-44%): glorp, grumble, klak, frrr, croak

Каждый агент "владеет" своим контекстом:
```
social_11: squee → рифтовый контекст (0,2,3,2,0,3) с 93-95%
social_12: drrrn → (0,3,3,3,0,3) с 85-89%
social_15: glorp → (3,0,0,2,3,3) с 94%
social_13: croak → (3,0,0,2,2,3) с 94%
social_14: zzzt  → (0,0,0,0,2,0) с 95%
```

### 6. ЭКОНОМИКА (позитив)

`economic_delta` стабильно положительный (100-300) в последних эпохах. Агенты зарабатывают больше чем тратят. Экономика работает, **проблема именно в языке**.

---

## ДИАГНОЗ

### Что работает:
1. Social координация реальна — social стабильно получают больше наград
2. Словарь стабилизировался на ~88 словах — здоровый размер
3. Экономика положительная
4. Специализация контекстов — агенты учат конкретные rift/water паттерны

### Что не работает:
1. **CSR в свободном падении** — агенты всё хуже понимают друг друга
2. **Полная потеря знаний при смерти** — главный bottleneck
3. **Нет композициональности** — язык голофрастический (один звук = один смысл)
4. **Смертность растёт экспоненциально** — мир слишком жёсткий
5. **Greedy хуже random** — стратегия не оптимальна в расширенном мире
6. **CSR считает greedy/random** — метрика искусственно занижена

### Аналогия:
Это цивилизация с постоянной амнезией — каждое поколение учит всё заново, и с каждым разом немного хуже. Без механизма передачи знаний между поколениями язык обречён на деградацию.

---

## ЗАДАНИЕ

Мне нужен **детальный план лечения** этой системы. Для каждой из 5 проблем ниже:

### Проблема 1: Потеря знаний при смерти (Knowledge Inheritance)

Сейчас при смерти/turnover агент теряет ВСЁ. Нужен механизм передачи знаний.

**Варианты для анализа:**
- A) **Cultural Cache** — группа у рифта хранит "shared dictionary", новый агент скачивает при контакте
- B) **Mentor System** — при ребёрне агент копирует 30-50% весов от ближайшего живого social агента
- C) **Genetic Inheritance** — при смерти "seed" знаний (top-10 ассоциаций с highest confidence) передаётся в pool, новый агент стартует с seed
- D) **Population Memory** — сервер хранит running average production weights для каждого контекста, новый агент инициализируется от популяционного среднего

**Вопросы:**
- Какой вариант лучше всего воспроизводит реальные механизмы cultural transmission?
- Как не дать наследованию knowledge убить language drift (язык должен меняться, не застывать)?
- Оптимальный % наследования? 30%? 50%? Зависит от чего?
- Есть ли papers по knowledge inheritance в emergent communication?

### Проблема 2: CSR падает (Communication Breakdown)

CSR 99% → 57%. Возможные причины:
- Greedy/random агенты в выборке (не реагируют на звуки → занижают CSR)
- Новорождённые агенты не понимают язык → слышат звук, не двигаются к рифту
- Language drift от постоянного turnover → разные агенты знают разные "диалекты"

**Вопросы:**
- Считать CSR только для social агентов с experience > N тиков?
- Или CSR по парам (speaker→listener), где listener = social?
- Как отличить "CSR падает потому что язык плохой" от "CSR падает потому что метрика включает non-speakers"?
- Нужна ли дополнительная метрика (Pairwise Communication Accuracy)?

### Проблема 3: Смертность x11 (Predator Escalation)

Social агенты кучкуются у рифтов → плотность → хищники → массовые убийства → потеря знаний → ещё хуже язык.

**Вопросы:**
- Group defense bonus (группа 3+ отпугивает хищников)?
- Или cap на spawn rate хищников в зоне?
- Или "убежища" (safe zones) рядом с рифтами?
- Как сбалансировать чтобы смерть осталась значимой но не уничтожала культуру?
- Какой death rate "здоровый" для language evolution? (по литературе iterated learning)

### Проблема 4: Нет композициональности (PosDis/BosDis ≈ 0)

Язык голофрастический — каждое высказывание = один неделимый смысл. Нет структуры.

**Вопросы:**
- Достаточно ли 30 звуков для ~200 контекстов чтобы ВЫНУДИТЬ комбинации?
- Может нужно УМЕНЬШИТЬ звуки до 8-10 чтобы создать expressivity pressure?
- Нужен ли явный incentive для multi-sound сообщений (бонус за 2+ звуков)?
- Может проблема в ContextDiscoverer — 200 контекстов слишком много для 30 звуков?
- Chaabouni 2020 показал что compositionality требует specific pressure — какой именно?
- Может нужен bottleneck: ограничить bandwidth (max 2 звука/тик) чтобы вынудить эффективность?

### Проблема 5: Greedy хуже Random

В некоторых эпохах random агенты обходят greedy. Greedy стратегия: молча идти к ближайшему рифту + убегать от хищников.

**Вопросы:**
- Почему random иногда лучше? Случайное распределение покрывает больше рифтов?
- Должен ли greedy подслушивать social (eavesdropping — слышит звуки, движется к ним, но не говорит)?
- Или это не баг а фича — показывает что social cooperation > individual optimization?

---

## ФОРМАТ ОТВЕТА

Для каждой из 5 проблем:

### Проблема N — [название]

**Диагноз** (что именно ломается и почему, с привязкой к теории/papers)

**Рекомендованное решение** (одно основное, с обоснованием)

**Альтернативы** (1-2 с trade-offs)

**Параметры** (конкретные числа: % наследования, пороги, cap'ы)

**Псевдокод** (Python-like, реализуемый без ML-фреймворков)

**Метрики успеха** (как понять что починили)

**Риски** (что может пойти не так)

---

В конце:

### Порядок реализации
Какие фиксы делать первым, вторым, третьим. Какие зависят друг от друга. Что можно делать параллельно.

### Предсказания
Если реализовать все 5 фиксов — какие метрики ожидаем через 64 эпохи? CSR? MI? PosDis? Обоснуй цифры.

### Открытые вопросы
Что ещё ты заметил в данных что мы не спросили? Какие дополнительные эксперименты нужны?
